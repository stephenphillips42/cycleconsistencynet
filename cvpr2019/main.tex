\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
% Include other packages here, before hyperref.
\usepackage[outdir=./]{epstopdf}

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

% \cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

%% Custom control sequences
\let\oldPr\Pr
\newcommand{\bR}{\mathbb{R}}
\renewcommand*{\Pr}[1]{\mathbb{P}\left( #1 \right)}
\newcommand{\mat}[1]{\mathbf{#1}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ifcvprfinal\pagestyle{empty}\fi
\setcounter{page}{4321}
\begin{document}

%%%%%%%%% TITLE
\title{Learning Multiple View Feature Representations}

\author{Stephen Phillips, Kostas Daniilidis \\
GRASP Labratory, University of Pennsylvania\\
{\tt\small \{stephi, kostas\}@seas.upenn.edu}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
% \and
% Second Author\\
% Institution2\\
% First line of institution2 address\\
% {\tt\small secondauthor@i2.org}
}

\maketitle
%\thispagestyle{empty}

% Papers, excluding the references section,
% must be no longer than eight pages in length. The references section

%%%%%%%%% ABSTRACT
\begin{abstract}
   % Put abstract here
   % OK I hate this start but we will work on it.
   (Work in progress) In this work we present a learning technique for refining multi-image matches in an unsupervised fashion.
   We formulate the multi-image matching problem as a graph embedding problem then use recent work in Graph Neural Networks to learn the appropriate embedding function.
   Since ground truth correspondence is difficult or expensive to come by in many real world datasets, we use cycle consistency as our loss function.
   Additional losses can be added if more information is available in the training set for better test performance.
   To the best of our knowledge, no other works have used learning for multi-image feature matching.
   Our experiments show that our method is competitive with other optimization based approaches.
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}

% TODO: Add more citations
Feature matching is an essential part of many geometric computer vision applications.
Much work has been done on image matching for the last several decades \cite{fischler1981random}.
However we still have not fully answered the question: What are the best features of an image to capture multiple views of the same scene?
Recently deep learning has revolutionized how image features are computed \cite{yi2016lift}, and we would like to leverage this to compute better scene features.
Typically when applied to this area, deep neural networks (DNNs) are trained with photometric losses.
Photometric losses make the brightness constancy assumption - can we learn using multi-view constraints directly?

Unfortunately there are obstacles to applying multi-view constraints directly to learning. 
To train networks, we need a large amount of labelled data.
In the case of multi-image feature matching, one would need to hand label point correspondences between images, which is difficult and expensive to obtain.
Mutli-view constraints are formulated in terms of sparse features, thus traditional convolutional deep neural nets (CNNs) are not designed to handle such input.

In this work we propose to solve these problems using a Graph Neural Network (GNN) to operate on the correspondence graph, agnostic to the method used to compute the correspondence graph. We use an self-supervised loss, the cycle consistency loss, to train the network. We also add in side geometric losses used to help training, where the geometric information is not available at train time.
Our contributions our:
\begin{itemize}
\item A novel architecture for feature multi-image feature matching using GNNs with graph embeddings
\item Using the self-supervised cycle consistency loss
\item Test geometric consistency losses toward the training
\item Perform experiments on the Rome16K dataset to test the effectiveness of our baseline
\end{itemize}




\begin{figure}[t]
\begin{center}
  \fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
  % \includegraphics[width=0.8\linewidth]{figures/experiments.eps}
\end{center}
   \caption{Example of caption.  It is set in Roman so that mathematics
   (always set in Roman: $B \sin A = A \sin B$) may be included without an
   ugly clash.}
\label{fig:long}
\label{fig:onecol}
\end{figure}


%-------------------------------------------------------------------------
\section{Related Work}

TODO

% When placing figures in \LaTeX, it's almost always best to use
% \verb+\includegraphics+, and to specify the  figure width as a multiple of
% the line width as in the example below
% {\small\begin{verbatim}
%    \usepackage[dvips]{graphicx} ...
%    \includegraphics[width=0.8\linewidth]
%                    {myfile.eps}
% \end{verbatim}
% }


%------------------------------------------------------------------------
\section{Method}
Our goal is to learn optimal features that capture multiple image views.
We assume we have an initial set of features matches, represented as a graph, $\mathcal{G} = (\mathcal{V}, \mathcal{E})$.
Each vertex $v$ of the graph is a feature, with its assocated descriptor $f_v$. 
The graph is represented by its Weighted Adjacency Matrix $A(\mathcal{G}) \in \bR^{n \times n}$, and its degree matrix $D(\mathcal{G}) \in \bR^{n \times n}$ (positive diagonal).
Combined the features $f_v$ from each of the vertices we can get an embedding matrix $E_0$.
We can also add other knowledge we will have at test time.
Putative correspondences are computed from these, and represented by weighted edges, the weight giving the strength of the match.
While there are many interesting methods for computing these putative correspondences, we do not explore them in this work.
The graph structure does not have the properties of a Eulcidean domain (such as an image) we cannot use standard CNNs to learn features for this task.
Thus we need to use graph convolutions to learn feature representations on this space.

\subsection{Graph Neural Networks}
Much attention has been given to graph neural networks (GNNs) recently
\cite{bronstein2017geometric, bruna2013spectral, defferrard2016convolutional, kipf2016semi, scarselli2009graph, gama2018mimo, gama2018convolutional}.
For our purpose we will need a method that can handle different graph structures as input, thus we cannot resort to spectral graph convolution methods.
Since our goal is to describe correspondence of each of the nodes, we also cannot use pooling of the nodes.
\begin{align}
      L =&\; (D + I)^{-1/2} (A + I) (D + I)^{-1/2} \\
E_{k+1} =&\; \sigma\left(L E_k W_k \right)
\end{align}
Here $\sigma$ is the non-linearity (typically a $relu$), and $W_k$ are the learned weights. 
The matrix $L$ is analogous to the graph Laplacian, and is used to encode the structure of the graph.
It is with $L$ that the graph convolution is performed.
However, this is limited to convolutions over a one-hop neighborhood of a node.
For simplicity we restrict ourselves to this for now, though in principle we could use higher hop neighborhoods \cite{gama2018convolutional}.
To train this we use a cycle consistency.

\subsection{Cycle Consistency}
If the pairwise matches are globally consistent, then we can say that, for all $i, j, k$:
\begin{equation}
\mat{M}_{ij} = \mat{M}_{ik} \mat{M}_{kj}
\label{eq:cycconsist1}
\end{equation}
In other words, the matches between two images stays the same no matter what path is taken to get there. 
This constraint is known as \textit{cycle concistency}, and has been used in a number of recent works to optimze for global consistency \cite{zhou2015multi, wang2017multi, leonardos2016distributed}.
Stated in this form, there are $O(n^3)$ cycle consistency constraints to check.
A more elegant way to represent cycle consistency is to first create a `universe' of features that all images match to.
Then one can match each set of features $X_i$ to the universe, denoted $\mat{X}_i$.
Then the cycle consistency becomes:
\begin{equation}
\mat{M}_{ij} = \mat{X}_{i}\mat{X}_{j}^\top
\label{eq:cycconsist2}
\end{equation}

In the case, we try to learn embeddings that map to the $\mat{X}_i$ - learn the universe of features via our embeddings.
Thus our loss would be 
\begin{equation}
\mathcal{L}(A, E_n) = \mathcal{D}(A, E_nE_n^\top)
\end{equation}
Here $\mathcal{D}$ could be an $L_2$ loss, $L_1$ loss, or many others. 
This essential models that features $i$ and $j$ match with probability $(E_n)_i \cdot (E_n)_j$
which is proporitional to $A_{ij}$ with some noise.


%------------------------------------------------------------------------
\section{Experiments}

\begin{figure*}
\begin{center}
  % \fbox{\rule{0pt}{2in} \rule{.9\linewidth}{0pt}}
  \includegraphics[width=0.8\linewidth]{figures/experiments01-eps-converted-to.pdf}
  \end{center}
     \caption{Example of a short caption, which should be centered.}
  \label{fig:short}
\end{figure*}

\subsection{Rome 16K Graph Dataset}
% Filler for now.
% TODO: Actually run tests on all these with different loss functions
We extract image triplets, quadtruplets, and quintuplets with overlap of 80 points or more to test our algorithm on. For the normal datasets, we extracted 80 points established as corresponding in the bundle adjument given in the Rome16K dataset. For the outlier datasets, we take 79 correspondences and 1 non-corresponding point in each image.

We test with various loss functions, including ablation studies on various geometric loss functions.

% leaderConsensus.m  MatchALSTestErrors.txt  mmatch_CVX_ALS.m  mmatch_QP_PG.m  mmatch_spectral.m  PGDDS.m  PGDDSTestErrors.txt  print_errors.py  run_tests.m  SpectralTestErrors.txt
\begin{table*}
\begin{center}
\begin{tabular}{|l|c|c|c|}
\hline
Method & L1 Loss & L2 Loss & BCE Loss \\
\hline\hline\hline
Spectral                                  & 1.000e-3 & 1.000e-3 & 1.000e-3 \\ \hline
MatchALS                                  & 1.000e-3 & 1.000e-3 & 1.000e-3 \\ \hline
PGDDS                                     & 1.000e-3 & 1.000e-3 & 1.000e-3 \\ \hline
GNN, 12 Layers, w/o Geometric Side Losses & 1.000e-3 & 1.000e-3 & 1.000e-3 \\ \hline
GNN, 12 Layers, w/ Geometric Side Losses  & 1.000e-3 & 1.000e-3 & 1.000e-3 \\ \hline

\hline
\end{tabular}
\end{center}
\caption{
Results on Rome16k Correspondence graphs.
Losses tested against ground truth correspondence graph adjacency matrices.
Our method was not trained on ground truth corresopndences but on unsupervised methods.
}
\end{table*}


%------------------------------------------------------------------------
\section{Conclusion}

We have shown a novel method for training feature matching. 

{\small
\bibliographystyle{ieee}
\bibliography{mybib}
}

\end{document}
