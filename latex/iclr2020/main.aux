\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{lowe2004distinctive}
\citation{fischler1981random}
\citation{wang2017multi}
\citation{yi2016lift}
\citation{battaglia2018relational}
\citation{battaglia2018relational}
\citation{zhou2015multi,leonardos2016distributed}
\citation{li2010location}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{lowe2004distinctive}
\citation{bay2006surf}
\citation{calonder2012brief}
\citation{mur2015orb}
\citation{fischler1981random}
\citation{suh2015subgraph,hu2016distributable}
\citation{pachauri2013solving}
\citation{arrigoni2017synchronization}
\citation{zhou2015multi}
\citation{wang2017multi}
\citation{leonardos2016distributed}
\citation{tron2017fast}
\citation{zach2010disambiguating}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  An illustration of the approach of this work. The Graph Neural Neural Network (GNN) (\cite  {battaglia2018relational}) takes as input the graph of matches and then outputs a low rank embedding of the adjacency matrix of the graph. The GNN operates on an embedding over the vertices of the graph. In the figure, the GNN vertex embeddings are represented by different colors. The final embedding is used to construct a pairwise similarity matrix, which we train to be a low dimensional cycle-consistent representation of the graph adjacency matrix, thus pruning the erroneous matches. We train the network using a reconstruction loss on the similarity matrix with the noisy adjacency matrix, and thus do not need ground truth matches. In addition, we can use geometric consistency information, such as epipolar constraints, to assist training the network. \relax }}{2}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:pipeline}{{1}{2}{An illustration of the approach of this work. The Graph Neural Neural Network (GNN) (\cite {battaglia2018relational}) takes as input the graph of matches and then outputs a low rank embedding of the adjacency matrix of the graph. The GNN operates on an embedding over the vertices of the graph. In the figure, the GNN vertex embeddings are represented by different colors. The final embedding is used to construct a pairwise similarity matrix, which we train to be a low dimensional cycle-consistent representation of the graph adjacency matrix, thus pruning the erroneous matches. We train the network using a reconstruction loss on the similarity matrix with the noisy adjacency matrix, and thus do not need ground truth matches. In addition, we can use geometric consistency information, such as epipolar constraints, to assist training the network. \relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Feature Matching}{2}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Multi-image Matching}{2}{subsection.2.2}}
\citation{zagoruyko2015learning}
\citation{yi2016lift}
\citation{brachmann2017dsac}
\citation{choy2016universal}
\citation{yi2018learning}
\citation{zhu2017unpaired}
\citation{bronstein2017geometric,bruna2013spectral,defferrard2016convolutional,kipf2017semi,scarselli2009graph,gama2018mimo,gama2018convolutional}
\citation{battaglia2018relational}
\citation{bruna2013spectral}
\citation{bronstein2017geometric,kipf2017semi,scarselli2009graph}
\citation{gama2018convolutional}
\citation{gama2018mimo,gama2018convolutional}
\citation{battaglia2018relational}
\citation{suh2015subgraph,yi2018learning}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Deep Learning for Matching}{3}{subsection.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Graph Neural Networks}{3}{subsection.2.4}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Method}{3}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Correspondence Graph}{3}{subsection.3.1}}
\newlabel{fig:1b}{{2a}{4}{Illustrated here is an example of how the geometric loss is computed for one feature.\relax }{figure.caption.2}{}}
\newlabel{sub@fig:1b}{{a}{4}{Illustrated here is an example of how the geometric loss is computed for one feature.\relax }{figure.caption.2}{}}
\newlabel{fig:geoconsist}{{2a}{4}{Illustrated here is an example of how the geometric loss is computed for one feature.\relax }{figure.caption.2}{}}
\newlabel{sub@fig:geoconsist}{{a}{4}{Illustrated here is an example of how the geometric loss is computed for one feature.\relax }{figure.caption.2}{}}
\newlabel{fig:3b}{{2b}{4}{\relax }{figure.caption.2}{}}
\newlabel{sub@fig:3b}{{b}{4}{\relax }{figure.caption.2}{}}
\newlabel{fig:geomloss}{{2b}{4}{\relax }{figure.caption.2}{}}
\newlabel{sub@fig:geomloss}{{b}{4}{\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  \textbf  {(a)} Errors are computed via absolute distance from the epipolar line, as expressed by (\ref  {eq:essential_constraint}) via the epipolar constraint. The epipolar line is the line of projection of the feature on the first image, projected onto to the second. The distance to this line on the second image indicates how likely that point is to correspond geometrically to the original feature. There can be false positives along the projected line, as shown by the square feature in the figure, but other points will be eliminated, such as the hexagonal feature. \textbf  {(b)} Training curves with and without Geometric Training loss, described in \ref  {eq:geom_cost2}. The geometric training loss improves testing performance. While the training is higher due to the additional loss terms, the ground truth L1 error is substantially better with the Geometric Loss. Best viewed in color. \relax }}{4}{figure.caption.2}}
\newlabel{fig:1}{{2}{4}{\textbf {(a)} Errors are computed via absolute distance from the epipolar line, as expressed by (\ref {eq:essential_constraint}) via the epipolar constraint. The epipolar line is the line of projection of the feature on the first image, projected onto to the second. The distance to this line on the second image indicates how likely that point is to correspond geometrically to the original feature. There can be false positives along the projected line, as shown by the square feature in the figure, but other points will be eliminated, such as the hexagonal feature. \textbf {(b)} Training curves with and without Geometric Training loss, described in \ref {eq:geom_cost2}. The geometric training loss improves testing performance. While the training is higher due to the additional loss terms, the ground truth L1 error is substantially better with the Geometric Loss. Best viewed in color. \relax }{figure.caption.2}{}}
\newlabel{fig:1a}{{3a}{4}{Illustration of the universe of features.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:1a}{{a}{4}{Illustration of the universe of features.\relax }{figure.caption.3}{}}
\newlabel{fig:universefeatures}{{3a}{4}{Illustration of the universe of features.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:universefeatures}{{a}{4}{Illustration of the universe of features.\relax }{figure.caption.3}{}}
\newlabel{fig:1b}{{3b}{4}{\relax }{figure.caption.3}{}}
\newlabel{sub@fig:1b}{{b}{4}{\relax }{figure.caption.3}{}}
\newlabel{fig:embeddingsviz}{{3b}{4}{\relax }{figure.caption.3}{}}
\newlabel{sub@fig:embeddingsviz}{{b}{4}{\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  \textbf  {(a)} Each feature in each image corresponds to a 3D point in the scene. We can construct cycle consistent embeddings of the features by mapping each one to the one-hot vector of its corresponding 3D point. While there can be many features, there are fewer 3D points and thus this corresponds to a low rank factorization of the correspondence matrix. \textbf  {(b)} Visualization of the learned embeddings. On the left we have the raw outputs, which are difficult to interpret. In the center, we rotated the features to best match the ground truth for a more interpretable visualization. On the right, we have the ground truth embeddings, given as indicator vectors for which feature in the world the points correspond to. Best viewed in color. \relax }}{4}{figure.caption.3}}
\newlabel{fig:1}{{3}{4}{\textbf {(a)} Each feature in each image corresponds to a 3D point in the scene. We can construct cycle consistent embeddings of the features by mapping each one to the one-hot vector of its corresponding 3D point. While there can be many features, there are fewer 3D points and thus this corresponds to a low rank factorization of the correspondence matrix. \textbf {(b)} Visualization of the learned embeddings. On the left we have the raw outputs, which are difficult to interpret. In the center, we rotated the features to best match the ground truth for a more interpretable visualization. On the right, we have the ground truth embeddings, given as indicator vectors for which feature in the world the points correspond to. Best viewed in color. \relax }{figure.caption.3}{}}
\citation{bruna2013spectral}
\citation{kipf2017semi,defferrard2016convolutional,gama2018mimo,gama2018convolutional}
\citation{gama2019convolutional}
\citation{scarselli2009graph}
\citation{battaglia2018relational}
\citation{battaglia2016interaction}
\citation{battaglia2018relational}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Graph Neural Networks}{5}{subsection.3.2}}
\citation{zhou2015multi,wang2017multi,leonardos2016distributed}
\citation{tron2014quotient}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  Results on Synthetic correspondence graphs. The `Same Point Similarities' column is the mean and standard deviation of similarities for true corresponding points, while the `Different Point Similarities' is the same for points that do not correspond. For the `Same Point Similarities' column higher is better, and for `Different Point Similarities' lower is better. Losses tested against ground truth correspondence graph adjacency matrices. Our method was not trained on ground truth correspondences but using unsupervised methods. \relax }}{6}{table.caption.4}}
\newlabel{fig:synthtable}{{1}{6}{Results on Synthetic correspondence graphs. The `Same Point Similarities' column is the mean and standard deviation of similarities for true corresponding points, while the `Different Point Similarities' is the same for points that do not correspond. For the `Same Point Similarities' column higher is better, and for `Different Point Similarities' lower is better. Losses tested against ground truth correspondence graph adjacency matrices. Our method was not trained on ground truth correspondences but using unsupervised methods. \relax }{table.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Cycle Consistency}{6}{subsection.3.3}}
\newlabel{eq:cycconsist1}{{3}{6}{Cycle Consistency}{equation.3.3}{}}
\newlabel{eq:cycconsist2}{{4}{6}{Cycle Consistency}{equation.3.4}{}}
\newlabel{eq:rotinvar}{{3.3}{6}{Cycle Consistency}{equation.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Geometric Consistency Loss}{6}{subsection.3.4}}
\newlabel{eq:essential_constraint}{{6}{6}{Geometric Consistency Loss}{equation.3.6}{}}
\citation{zhou2015multi}
\citation{leonardos2016distributed}
\citation{pachauri2013solving}
\citation{zhou2015multi}
\citation{leonardos2016distributed}
\citation{pachauri2013solving}
\citation{kipf2017semi}
\citation{kingma2014adam}
\citation{tensorflow2015}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces  Results on Rome16K Correspondence graphs, showing the mean and standard deviation of the $L_1$ and $L_2$. Our method was not trained on ground truth correspondences but using unsupervised methods and geometric side losses. Thus we test against ground truth correspondence graph adjacency matrices computed from the bundle adjustment output. Our method performs better than 25 iteration of the MatchALS (\cite  {zhou2015multi}) method, but does not perform as well as 50 iterations. We do not perform as well as the Projected Gradient Descent Doubly Stochastic (PGDDS) (\cite  {leonardos2016distributed}) but we perform significantly faster than them. We perform better than a simple eigenvalue based method (\cite  {pachauri2013solving}). Note that we perform much better in $L_1$ performance rather than $L_2$, as we optimized the network weights using an $L_1$ loss. \relax }}{7}{table.caption.5}}
\newlabel{tab:rome16ktab}{{2}{7}{Results on Rome16K Correspondence graphs, showing the mean and standard deviation of the $L_1$ and $L_2$. Our method was not trained on ground truth correspondences but using unsupervised methods and geometric side losses. Thus we test against ground truth correspondence graph adjacency matrices computed from the bundle adjustment output. Our method performs better than 25 iteration of the MatchALS (\cite {zhou2015multi}) method, but does not perform as well as 50 iterations. We do not perform as well as the Projected Gradient Descent Doubly Stochastic (PGDDS) (\cite {leonardos2016distributed}) but we perform significantly faster than them. We perform better than a simple eigenvalue based method (\cite {pachauri2013solving}). Note that we perform much better in $L_1$ performance rather than $L_2$, as we optimized the network weights using an $L_1$ loss. \relax }{table.caption.5}{}}
\newlabel{eq:geom_cost}{{7}{7}{Geometric Consistency Loss}{equation.3.7}{}}
\newlabel{eq:geom_cost2}{{8}{7}{Geometric Consistency Loss}{equation.3.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{7}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Synthetic Graph Dataset}{7}{subsection.4.1}}
\citation{li2010location}
\citation{battaglia2018relational}
\citation{tensorflow2015}
\citation{kingma2014adam}
\citation{zhou2015multi}
\citation{leonardos2016distributed}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  Plot of the losses of the baselines at different iteration numbers. The line shows the mean of the graph while the translucent coloring shows the $25^{th}$ to $75^{th}$ percentiles. The ROC AUC curves remain fairly consistent while the L1 loss goes noticibly down after more iterations. Our method compares to 35-45 iterations of MatchALS, while only having 16 layers and 8 message passes. PGDDS performs better than us in $L_1$ but we perform similarly in the ROC AUC metric. These results still hold even when we change domains to the Graffiti dataset (see \ref  {sec:graffiti}). \relax }}{8}{figure.caption.6}}
\newlabel{fig:3}{{4}{8}{Plot of the losses of the baselines at different iteration numbers. The line shows the mean of the graph while the translucent coloring shows the $25^{th}$ to $75^{th}$ percentiles. The ROC AUC curves remain fairly consistent while the L1 loss goes noticibly down after more iterations. Our method compares to 35-45 iterations of MatchALS, while only having 16 layers and 8 message passes. PGDDS performs better than us in $L_1$ but we perform similarly in the ROC AUC metric. These results still hold even when we change domains to the Graffiti dataset (see \ref {sec:graffiti}). \relax }{figure.caption.6}{}}
\newlabel{fig:errorlines}{{4}{8}{Plot of the losses of the baselines at different iteration numbers. The line shows the mean of the graph while the translucent coloring shows the $25^{th}$ to $75^{th}$ percentiles. The ROC AUC curves remain fairly consistent while the L1 loss goes noticibly down after more iterations. Our method compares to 35-45 iterations of MatchALS, while only having 16 layers and 8 message passes. PGDDS performs better than us in $L_1$ but we perform similarly in the ROC AUC metric. These results still hold even when we change domains to the Graffiti dataset (see \ref {sec:graffiti}). \relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Rome 16K Graph Dataset}{8}{subsection.4.2}}
\bibstyle{iclr2020_conference}
\bibdata{egbib}
\bibcite{tensorflow2015}{{1}{2015}{{Abadi et~al.}}{{Abadi, Agarwal, Barham, Brevdo, Chen, Citro, Corrado, Davis, Dean, Devin, Ghemawat, Goodfellow, Harp, Irving, Isard, Jia, Jozefowicz, Kaiser, Kudlur, Levenberg, Man\'{e}, Monga, Moore, Murray, Olah, Schuster, Shlens, Steiner, Sutskever, Talwar, Tucker, Vanhoucke, Vasudevan, Vi\'{e}gas, Vinyals, Warden, Wattenberg, Wicke, Yu, and Zheng}}}
\bibcite{arrigoni2017synchronization}{{2}{2017}{{Arrigoni et~al.}}{{Arrigoni, Maset, and Fusiello}}}
\bibcite{battaglia2016interaction}{{3}{2016}{{Battaglia et~al.}}{{Battaglia, Pascanu, Lai, Rezende, et~al.}}}
\bibcite{battaglia2018relational}{{4}{2018}{{Battaglia et~al.}}{{Battaglia, Hamrick, Bapst, Sanchez-Gonzalez, Zambaldi, Malinowski, Tacchetti, Raposo, Santoro, Faulkner, et~al.}}}
\bibcite{bay2006surf}{{5}{2006}{{Bay et~al.}}{{Bay, Tuytelaars, and Van~Gool}}}
\bibcite{brachmann2017dsac}{{6}{2017}{{Brachmann et~al.}}{{Brachmann, Krull, Nowozin, Shotton, Michel, Gumhold, and Rother}}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Graffiti Dataset}{9}{subsubsection.4.2.1}}
\newlabel{sec:graffiti}{{4.2.1}{9}{Graffiti Dataset}{subsubsection.4.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{9}{section.5}}
\bibcite{bronstein2017geometric}{{7}{2017}{{Bronstein et~al.}}{{Bronstein, Bruna, LeCun, Szlam, and Vandergheynst}}}
\bibcite{bruna2013spectral}{{8}{2013}{{Bruna et~al.}}{{Bruna, Zaremba, Szlam, and LeCun}}}
\bibcite{calonder2012brief}{{9}{2012}{{Calonder et~al.}}{{Calonder, Lepetit, Ozuysal, Trzcinski, Strecha, and Fua}}}
\bibcite{choy2016universal}{{10}{2016}{{Choy et~al.}}{{Choy, Gwak, Savarese, and Chandraker}}}
\bibcite{defferrard2016convolutional}{{11}{2016}{{Defferrard et~al.}}{{Defferrard, Bresson, and Vandergheynst}}}
\bibcite{fischler1981random}{{12}{1981}{{Fischler \& Bolles}}{{Fischler and Bolles}}}
\bibcite{gama2019convolutional}{{13}{}{{Gama et~al.}}{{Gama, Marques, Leus, and Ribeiro}}}
\bibcite{gama2018convolutional}{{14}{2018{a}}{{Gama et~al.}}{{Gama, Leus, Marques, and Ribeiro}}}
\bibcite{gama2018mimo}{{15}{2018{b}}{{Gama et~al.}}{{Gama, Marques, Ribeiro, and Leus}}}
\bibcite{hu2016distributable}{{16}{2016}{{Hu et~al.}}{{Hu, Thibert, and Guibas}}}
\bibcite{kingma2014adam}{{17}{2014}{{Kingma \& Ba}}{{Kingma and Ba}}}
\bibcite{kipf2017semi}{{18}{2017}{{Kipf \& Welling}}{{Kipf and Welling}}}
\bibcite{leonardos2016distributed}{{19}{2016}{{Leonardos et~al.}}{{Leonardos, Zhou, and Daniilidis}}}
\bibcite{li2010location}{{20}{2010}{{Li et~al.}}{{Li, Snavely, and Huttenlocher}}}
\bibcite{lowe2004distinctive}{{21}{2004}{{Lowe}}{{}}}
\bibcite{mur2015orb}{{22}{2015}{{Mur-Artal et~al.}}{{Mur-Artal, Montiel, and Tardos}}}
\bibcite{pachauri2013solving}{{23}{2013}{{Pachauri et~al.}}{{Pachauri, Kondor, and Singh}}}
\bibcite{scarselli2009graph}{{24}{2009}{{Scarselli et~al.}}{{Scarselli, Gori, Tsoi, Hagenbuchner, and Monfardini}}}
\bibcite{suh2015subgraph}{{25}{2015}{{Suh et~al.}}{{Suh, Adamczewski, and Mu~Lee}}}
\bibcite{tron2014quotient}{{26}{2014}{{Tron \& Daniilidis}}{{Tron and Daniilidis}}}
\bibcite{tron2017fast}{{27}{2017}{{Tron et~al.}}{{Tron, Zhou, Esteves, and Daniilidis}}}
\bibcite{wang2017multi}{{28}{2017}{{Wang et~al.}}{{Wang, Zhou, and Daniilidis}}}
\bibcite{yi2016lift}{{29}{2016}{{Yi et~al.}}{{Yi, Trulls, Lepetit, and Fua}}}
\bibcite{yi2018learning}{{30}{2018}{{Yi et~al.}}{{Yi, Trulls, Ono, Lepetit, Salzmann, and Fua}}}
\bibcite{zach2010disambiguating}{{31}{2010}{{Zach et~al.}}{{Zach, Klopschitz, and Pollefeys}}}
\bibcite{zagoruyko2015learning}{{32}{2015}{{Zagoruyko \& Komodakis}}{{Zagoruyko and Komodakis}}}
\bibcite{zhou2015multi}{{33}{2015}{{Zhou et~al.}}{{Zhou, Zhu, and Daniilidis}}}
\bibcite{zhu2017unpaired}{{34}{2017}{{Zhu et~al.}}{{Zhu, Park, Isola, and Efros}}}
