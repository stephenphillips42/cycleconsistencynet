\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv_rebuttal}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\iccvPaperID{****} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Rebuttal to ``All Graphs Lead to Rome''}  % **** Enter the paper title here

\maketitle
\thispagestyle{empty}


%%%%%%%%% BODY TEXT - ENTER YOUR RESPONSE BELOW
Thank you to all the reviewers for all of your constructive comments and feedback.
We will fix all minor typos. 
We hope to address the more important points of criticism here.
% Thank you to all the reviewers for all of your constructive comments and feedback. We fully understand your concerns and we elaborate on them here. We kindly ask you to trust us that the presentation will be clear in the camera-ready and to reward the novelty of the idea in your ratings.


%-------------------------------------------------------------------------
% \textit{Things are not what they seem}: This is an ominous quote that makes things appear much more dramatic.
\textbf{(R1)}
\textit{The network is evaluated on generated synthetic data and on triplets and quadruplets of real data from the Rome 16K dataset}, and
\textit{The only experiments described are on randomly generated synthetic data an on image triplets and quadruplets of real data}, and
\textit{Moreover, the experiments are limited.}
:
This was an unfortunate misunderstanding.
There was a mistake written on line 700 where we wrote `triplets and quadruplets' instead of `6-tuples and 10-tuples'.
If you look at Figures 5 and 6 and Table 2, you can see we correctly label them as 6 and 10 views, and thus our method works are larger scales than what the typo would imply.

\textbf{(R1)} \textit{The very related approach: Disambiguating visual relations using loop constraints, Zach et al. CVPR 2010, is not discussed}:
This paper seems to be focusing on pose graph optimization and thus we overlooked it.
We will cite it in the final version paper.

\textbf{(R1)} \textit{There has been earlier work which used more than than two images such as, Learning Dense Correspondence via 3D-guided Cycle Consistency, Zhou et al. CVPR 2016}:
We should have cited this.
However this work \cite{zhou2016learning} to our understanding only does cycle consistency between two images, using ground truth CAD models to gain longer cycles.
They never do cycle consistency on more than two images. 

\textbf{(R1)} \textit{I feel that this statement is a bit broad and might be overstating the contribution, works such as "LIFT: Learned Invariant Feature Transform" or "Learned Multi-Patch Similarity" seem to already tackle some aspects of this problem}:
% We are sorry we did not make this clearer.
What is meant by this is that this is the first algorithm we know of learning the matching algorithm itself on sparse features (not too clear with our language) on more than 2 images (hence multi-image).
LIFT \cite{yi2016lift} clearly does feature matching, and thus we cite it, however it only does pairwise image matching.
You are correct in that we did not cite `Learned Multi-patch Similarity' \cite{hartmann2017learned}, which is an important step for our research question, so we will cite it in the paper.
We will update the referenced sentence in the paper to say `To the best of our knowledge, this work is the first to apply Graph Neural Networks to the sparse feature matching problem on more than 2 images'.
% TODO: That paper only has 19 citations which is why we did not find it but it does pre-date us. Drat

\textbf{(R1)} \textit{It is not very clear how this approach can be used to improve geometric computer vision problems such as SfM as mentioned in the introduction} and \textbf{(R3)} \textit{It would be nice to see how the proposed algorithm can benefit many practical computer vision tasks, such as 3D reconstruction using SfM}:
We feel this can be used in existing SfM pipelines before bundle adjustment to improve matching.
Also it can be used to improve works such as \cite{zhu2015single} for reconstruction using semantic features in an end to end fashion.
We hope to address this more fully with future work, and integrate it into a SfM pipeline.



%------------------------------------------------------------------------
% \textit{So it has come to this}: This is another ominous quote that while basically vacuous makes everything appear much more dramatic.
\textbf{(R2)} \textit{Line 417 says "we use the mean function" and "we use MLPs" but it is unclear how that corresponds to the equations above. At least in the supplemental material, they should prove a more precise and complete explanation of the neural network architecture}:
Indeed the sentence you specify could be made clearer and we can add more detail in the paper and supplemental material to make it clearer, adding details on layer and filter sizes.
When we say `we use the mean function', we mean that to aggregate the edge features into the node features we just take the mean of the transformed features as opposed to for example max.
What we mean by `we use MLPs' is instead of taking a linear transformation of the node and edge embeddings between passes, we could learn a nonlinear transform using MLP.

\textbf{(R2)} \textit{The matching matrices M in Equation 5 are not explained -- one has to read the related work in order to understand what they are} and \textit{Also, Equation 5 is only valid if all 3D points are visible in all views under consideration}:
We can more clearly define the matching matrices.
And Equation 5 can hold more generally if you allow rows of all zeros for places where there are no matches.
However this is not made clear, and we will clarify it more when we clarify our language about the matching matrices.

\textbf{(R2)} \textit{ Line 517 mentions $E_i$, $E_j$ but they are not used in Equation 12?}:
No that is just a typo, thank you for catching it.

%------------------------------------------------------------------------
% \textit{So it begins}: This also is an ominous quote that applies to most beginnings but makes things appear much more dramatic.
\textbf{(R3)} \textit{If we only look at a local image patch, without global/geometric constraints, there might exist multiple valid matches for a candidate patches ... How does the proposed GNN method handle such cases?}:
This is where the Geometric Consistency Loss would come in, as it would disambiguate such features.
We will make this more explicit in the paper.
In cases where such geometric information is not available, we could learn features with more information about the intra-image feature matches.
This could help disambiguate visually similar features within the same image, and is a direction we are working on now.





% \begin{figure}[t]
% \begin{center}
% \fbox{\rule{0pt}{1.8in} \rule{0.9\linewidth}{0pt}}
%    %\includegraphics[width=0.8\linewidth]{egfigure.eps}
% \end{center}
%    \caption{Example of caption.  It is set in Roman so that mathematics
%    (always set in Roman: $B \sin A = A \sin B$) may be included without an
%    ugly clash.}
% \label{fig:long}
% \label{fig:onecol}
% \end{figure}

% {\footnotesize
{\tiny
\bibliographystyle{ieee}
\bibliography{egbib}
}



\end{document}
