\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv_rebuttal}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\iccvPaperID{4115} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Rebuttal to ``All Graphs Lead to Rome''}  % **** Enter the paper title here

\maketitle
\thispagestyle{empty}


%%%%%%%%% BODY TEXT - ENTER YOUR RESPONSE BELOW
Thank you to the reviewers for all of your constructive comments and feedback.
We hope to address some concerns expressed by the reviewers here.
We will also address any concerns or typos not mentioned.

%-------------------------------------------------------------------------
\textbf{(R1)} \textit{Insufficient experiments}:
This was an unfortunate misunderstanding.
We accidentally reported on line 700 where we wrote `triplets and quadruplets' instead of `6-tuples and 10-tuples'.
In Figures 5 and 6 and Table 2, you can see we correctly label them as 6 and 10 views.
Thus our method works with a larger number of images as well.

\textbf{(R1)} \textit{Prohibitive size of embedding vector for large SfM}:
This is a limitation of many works using cycle consistency, such as works [32, 28, 19, 23] cited in our paper.
Learning cycle consistent subwindows can still be useful in filtering erroneous matches in a sliding window fashion.

\textbf{(R1)} \textit{Citing Zach et al 2010}:
This paper seems to be focusing on pose graph optimization and thus we did not include it in the related work.
This work handles cycle inconsistencies by solving a convex relaxation of probabilistic inference over the validity of edges.
It requires composable geometric relations between each of the nodes in the graph, which we do not have with our feature matches at inference time.
Regardless, this is still very relevant and we will cite it in the final version paper.

\textbf{(R1)} \textit{Citing Zhou et al 2016}:
We will cite this in the camera-ready version.
% To our understanding this work does cycle consistency between only two images. %, using ground truth CAD models to gain longer cycles.
While methodology wise this paper uses cycle consistency, they learn cycle consistency of two images though ground truth CAD models, while our work enforces cycle consistent features through 3 or more views.

\textbf{(R1)} \textit{Regarding ``LIFT: Learned Invariant Feature Transform'' or ``Learned Multi-Patch Similarity''}:
LIFT ([29] in the paper) clearly does feature matching, and thus we cite it, however it only does pairwise image matching.
You are correct in that we did not cite `Learned Multi-patch Similarity' by Hartmann et al, which is an important step for our research question, so we will cite it in the paper.

\textbf{(R1)} and \textbf{(R3)} \textit{Applying this to SfM}:
Our approach could be incorporated in existing SfM pipelines before bundle adjustment to improve matching.
However this work shows more promise in reconstructing and matching semantic features, similar in Wang et al ([28] in the paper) but using pixels directly.
We hope to address this more fully with future work, and integrate it into a SfM pipeline.

\textbf{(R1)} \textit{Overstating the contribution}:
We will be careful to not overstate the contributions in camera-ready version.
Our intention was to state that this is the first algorithm we know of learning the matching algorithm itself on sparse features (not too clear with our language) on more than 2 images.
We will update the referenced sentence in the paper to say `To the best of our knowledge, this work is the first to apply Graph Neural Networks to the sparse feature matching problem on more than 2 images'.
Despite this, we appreciate the reviewers acknowledging the novelty of learning representations through correspondence and geometric constraints.

%------------------------------------------------------------------------
\textbf{(R2)} \textit{Meaning of "we use the mean function" and "we use MLPs"}
When we say `we use the mean function', we mean that to aggregate the edge features into the node features we just take the mean of the transformed features as opposed to the maximum.
What we mean by `we use MLPs' is instead of taking a linear transformation of the node and edge embeddings between passes, we could learn a nonlinear transform using MLP.
We will clarify this in the camera ready version.

\textbf{(R2)} \textit{More detail on architecture}:
Indeed the sentence you specify could be made clearer and we will add more details in the paper and supplemental material.
We will also publicly release our code and the implementation details in the supplemental.
% Right now we use 6 message passes through between the node and edge features, with the number of hidden nodes starting at 32 and doubling until flattening at 256. Between each message pass we process the features with a 2 layer MLP.

\textbf{(R2)} \textit{Explaining matching matrices Equation 5}:
We will more clearly define the matching matrices.
Equation 5 can hold more generally if you allow rows of all zeros for places where there are no matches.
However this is not made clear, and we will clarify it more when we clean up our language about the matching matrices.

\textbf{(R2)} \textit{$E_i$, $E_j$ not used in Equation 12?}:
No that is just a typo, thank you for catching it.

\textbf{(R2)} \textit{Only on par with state of the art}:
We agree that the contribution of this work is to allow deep learning to be applied to this problem, and to allow future works to build on top for further improvement on performance.
% TODO: Is this comment necessary?

%------------------------------------------------------------------------
\textbf{(R3)} \textit{Handling ambiguous matches when using purely local image patches}:
This is where the Geometric Consistency Loss would come in, as it would disambiguate such features.
We will make this more explicit in the paper.
In cases where such geometric information is not available, we could learn features with more information about the intra-image feature matches.
This could help disambiguate visually similar features within the same image, and is a very interesting direction for future work.

\textbf{(R3)} \textit{PGDDS being faster and more accurate}:
As we know from one pass inference on graph or geometry problems, it is difficult to outperform multi-iteration optimization methods.
The advantage our method has is allowing for end-to-end training to enable learning features from pixels directly, a direction we hope to pursue in future work.
In addition, PGDDS uses many optimizations between passes through the graph, so in future work we could use methods like OptNet by Amos et al ICML 2017 to help improve performance.


% {\footnotesize
% {\tiny
% \bibliographystyle{ieee}
% \bibliography{egbib}
% }



\end{document}
